Part 1. Implement data lake on GCP Cloud Datastore, Cloud Dataproc and BigQuery. 
Part 2. Try ELT processes (created python scripts and submit them as jobs in dataproc) with all three types of storage learned in week 
Part 3. Try with structured data (csv, parquet,orc), unstructured data (text excerpts from article, images), semi-structured data (json, xml). Use pyspark for loading and querying. 
Part 4. Write a python script to read a csv file and write it back to cloud storage in parquet format using pyspark

<b>Part 4: </b>
Read the CSV file from Google Cloud and converted to Parquet file
[]!()

